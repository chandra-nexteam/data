link google colabs 

https://colab.research.google.com/drive/19qfAMpg_wRBgFW1WA-7Dc4TdG33c90x-?usp=sharing 

#Import Library 
import numpy as np 
import pandas as pd 
import matplotlib.pyplot as plt
import seaborn as sns

#Iport Data 

df=pd.read_csv("/content/harga_mobil.csv")
df 
#Data Cleaning  
df=df.drop(columns=["CarName"])
df 

df.info 
df.describe

#korelasi 
plt.figure(figsize=(25,25))
sns.heatmap(df.corr(),annot=True,cmap="Greys") 

## Data Preprosesing 

from sklearn.model_selection import train_test_split 
X=df.drop(columns="price")
y=df.price 

X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42) 
X_train.shape,X_test.shape,y_train.shape,y_test.shape

from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import OneHotEncoder , MinMaxScaler,StandardScaler,RobustScaler

numerical_pipeline=Pipeline([
    ("imputer",SimpleImputer(strategy='mean')),
    ('scaler',RobustScaler())
])

categorical_pipeline=Pipeline([
    ("imputer",SimpleImputer(strategy='most_frequent')),
    ('encode',OneHotEncoder())
])  
#masukin numerical pipeline berdasarkan korelasi yang paling berpengaruh, categorical masukin berdasarkan visualisasi.
from sklearn.compose import ColumnTransformer  
preprocessor= ColumnTransformer([ 
    ("numeric",numerical_pipeline,['enginesize','horsepower','curbweight','stroke']),
    ('categoric',categorical_pipeline,['carbody','aspiration','drivewheel'])
])
# karna regresi maka menggunakan RandomForestRegressor   
from sklearn.ensemble import RandomForestRegressor
pipeline=Pipeline([
        ("prep",preprocessor),
        ("algo",RandomForestRegressor())
])

parameter = {
    'algo__max_depth': [4, 5, 10],
    'algo__max_features': [2, 3],
    'algo__min_samples_leaf': [3, 4, 5],
    'algo__n_estimators': [100, 200, 300],
}

## Training 

from sklearn.model_selection import RandomizedSearchCV
model = RandomizedSearchCV(pipeline, parameter, cv=3, n_iter=50, verbose=1, random_state=42)
model.fit(X_train, y_train)

print(model.best_params_)
print(model.score(X_train, y_train), model.best_score_, model.score(X_test, y_test))

## metrics  

df_test=pd.DataFrame(y_test).reset_index(drop=True)
df_test

## predict 

df_test['prediction']=pd.DataFrame(model.predict(X_test))
df_test

#mae  
from sklearn.metrics import mean_absolute_error
mae= mean_absolute_error(df_test.price, df_test.prediction)
print("Mean absolute error:" + str(mae)) 

##MSE 
from sklearn.metrics import mean_squared_error 
mse= mean_squared_error(df_test.price, df_test.prediction)
print("Mean squared error" + str(mse)) 

#RSME 
from sklearn.metrics import mean_squared_error
from math import sqrt 
rmse = sqrt(mean_squared_error(df_test.price, df_test.prediction))


from sklearn.metrics import r2_score 
r2=r2_score(df_test.price, df_test.prediction)
print("R Square : " + str(r2))
print("Root Mean squared error: " + str(rmse))

# Rsquared 
from sklearn.metrics import r2_score 
r2=r2_score(df_test.price, df_test.prediction)
print("R Square : " + str(r2))
